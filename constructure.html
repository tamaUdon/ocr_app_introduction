<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Introduction: original OCR app</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/marx/2.0.4/marx.css">
    <link rel="stylesheet" type="text/css" href="http://alexgorbatchev.com/pub/sh/current/styles/shCoreEclipse.css"/>
    <script type="text/javascript" src="http://alexgorbatchev.com/pub/sh/current/scripts/shCore.js"></script>
    <script type="text/javascript" src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushPython.js"></script>
    <script type="text/javascript">SyntaxHighlighter.all();</script>
</head>

<body>
<main>
  <h1>設計・仕様</h1>
    <div>
        <h4>処理フロー</h4>
        <img src="./image/flow.png" alt="" width="300" hight="200">
        
    <h4>１．androidのカメラで画像を撮影</h4>
        <p>android studioを使い、javaで実装。<br>
            androidの標準カメラで写真を撮影し、Exif情報を取得し、回転処理を加える。<br>
            画像をflaskで作った機械学習APIにHttp通信でPOSTする。<br>
            レスポンスされたテキストをアプリ画面に表示する。<br>
        </p>
    <h4>２．flaskで機械学習APIを作成、文字認識</h4>
        <p>flask(python)で機械学習APIを作成。<br>
            windowsの英数字フォントデータを加工し、学習させ、重みデータを得る。<br>
            英数字の混ざったテキストを同時に認識することは難しいと判断("l"と"1","Z"と"2"など)し、<br>
            英字、数字を別モデルで学習させ、2種類の重みデータを得た。<br></p>
            
        <pre class="brush:py">
        #重みデータを作るコード
        </pre>
        <p>
            androidアプリで英字のみのテキストか、数字のみかをユーザーに選択してもらう。<br>
            選択されたボタンに応じて英字/数字の重みデータを読み込む。<br>
        </p>
        
        <pre class="brush:py">
            #英字選択の場合
            if weight == 'eng':
                nlist = alphabet_model.predict(np.array(X))
                for i, n in enumerate(nlist):
                    ans = n.argmax()
                    alphabet_dic = {i:chr(c) for i,c in enumerate(range(ord('A'),ord('Z')+1))}
                    alphabet_dic.update({i+26:chr(c) for i,c in enumerate(range(ord('a'),ord('z')+1))})
                res = alphabet_dic.get(ans)
                
                if res == None:
                    result.append(ans)

                else:
                    result.append(res)
            
            #数字選択の場合
            elif weight == 'num':
                nlist = numeral_model.predict(np.array(X))
                for i, n in enumerate(nlist):
                    ans = n.argmax()
                    result.append(ans)
                    
            return result
        </pre>
        <p>
            学習時の認識精度は89.5%であった。<br><br>
            フォントから切り取った学習用画像データを確認したところ、"i" の上部 "・" の部分のみが<br>
            認識されており、この誤認識画像が正答率を下げているようだ。<br>
            今回はプログラムの完成を目標としており、高い認識精度は求めない。<br>
            実機テストでは、画像のゆがみや明暗の差によるテキスト誤検出により認識精度が下がることが認められた。<br>
            後述の画像処理に重点を置き、より正しくテキストを検出させることで、実機テストでもこの認識精度に近づけることにした。
        </p>
        <br>
    <h4>３．画像処理</h4>
        <p>ぼかし、二値化、回転(画像のゆがみ補正)をOpenCVで実装。<br>
            これらの処理を通すことで、後の文字認識の精度を上げる。<br>
        </p>
        <img src="./image/num_sample.jpg" alt="" width="300" hight="200">
        <p>↓(元画像)</p>
        <img src="./image/thresh_sample.png" alt="" width="300" hight="200">
        <p>↓(二値化し、ノイズを緩和した)</p>
        <img src="./image/rectangle_sample.png" alt="" width="300" hight="200">
        <p>(二値化画像からテキストの外接矩形を検出し、元画像に書き出したもの)</p>
        
        <pre class="brush:py">
        #グレイスケール化、平滑化、二値化
        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) 
        blur = cv2.GaussianBlur(gray, (5, 5), 0) 
        thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 1, 9, 4)
        </pre>
        <p>
            adaptive Threshold(二値化処理)のBlock Size, C(減算定数)は試行錯誤して決定した。<br>
            小さすぎる・大きすぎる矩形の処理を飛ばし、左上から順に矩形を並べ替え、認識させる。<br><br>
        </p>
        
        <h5>クラスタリング処理の前に、AKAZEによる特徴点検出を行う。</h5><br>
        <p>テキスト一文字につき中点一つを取って、クラスタリングを行ったが、精度が思うように上がらなかった。<br>
            座標データが少なすぎることが原因と思われたので、AKAZEで特徴点座標を多く得ることにする。<br>
        </p>
        <img src="./image/akaze.png" alt="" width="300" hight="200">
        <p>
        特徴点を画像上にプロッティングしたもの。<br>
        これだけ座標があればうまくクラスタリングできそうだ。<br>
        </p>
        <pre class="brush:py">
        #AKAZEで特徴点検出
        
        kp_array = np.empty((0,2), int)
        
        akaze = cv2.AKAZE_create()
        keypoints = akaze.detect(thresh)
        for marker in keypoints:
            #akaze_im = cv2.drawMarker(im, tuple(int(i) for i in marker.pt),color=(0, 255, 0))
            kp_array = np.concatenate([kp_array, np.array([marker.pt])], 0)
        #VBGMM
        bgmm = BayesianGaussianMixture(n_components=3, 
                                       weight_concentration_prior_type='dirichlet_process')
        bgmm = bgmm.fit(kp_array)
        cluster = bgmm.predict(kp_array)
        
        </pre>
        <p>
        参考url:<a href ="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html">https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html</a><br>
        ここでは最大3つのクラスタになるようn_components = 3 とした。<br>
        </p>
        <h5>次に、VBGMMによるクラスタリングを行う。</h5>
        <p>複数行にわたる文字列(改行あり文字列)の改行、空白を認識させるため、<br>
            VBGMM(Variational Bayesian Gaussian Mixture)によるクラスタリング処理を実装する。<br><br>
            
            #プロッティングしたグラフ挿入<br><br>
            
            ラベルデータやクラスタ数が不明でもクラスタリングが可能なためVBGMMを選択した。<br>
            複数行を認識させ、後述の処理で一行ずつ傾きを算出し、画像のゆがみを補正する。<br>  
        </p>
        
        
        <h5>次に、画像のゆがみを補正するため傾いている角度だけ回転させる。</h5>
        <p>
        横向きの画像や天地逆の画像は、android側でExif情報を読み取って補正できるが、<br>
        撮影した文字列自体が斜めに傾いている場合は、予測精度が落ちてしまう。<br>
        そのため、検出した特徴点の座標から文字列の傾きを算出し、アフィン変換で回転補正をかけた。<br>
        結果、予測間違いを減らすことに成功した。
        </p>
        <pre class="brush:py">
        

    def _img_rotate(im):
        
        avg_gradient = 0
        #特徴点のx,y座標を取り出す
        for i in range(len(list_keypoints_x)):
            kp_x = np.array(list_keypoints_x[i])
            kp_y = np.array(list_keypoints_y[i])
            
            #最小二乗法で直線の傾きを取得する
            #a=傾き,b=切片
            #傾きの絶対値の最大値を取得
            ones = np.array([kp_x,np.ones(len(kp_x))])
            ones = ones.T
            a,b = np.linalg.lstsq(ones,kp_y)[0]
            gradients.append(a)
        max_gradient = gradients[np.argmax(np.abs(gradients))]
        
        #画像回転
        global thresh
        rows,cols = thresh.shape
        d = math.degrees(avg_gradient)
        M = cv2.getRotationMatrix2D((cols/2,rows/2),d,1)
        thresh = cv2.warpAffine(thresh,M,(cols,rows))
        
        </pre>
        <img src="./image/original-th.png" alt="" width="300" hight="200">
        <p>文字列が傾いた元画像を二値化した画像</p>
        <p>それぞれのクラスタから算出した傾きa1 = -0.3416542173583762, a2=-0.2675808205604371, a3 = -15.331251696760448(単位:ラジアン,n_components = 3 の場合)</p>
        <img src="./image/rotate.png" alt="" width="300" hight="200">
        <p>回転処理をかけた画像</p>
        <!--<img src="./image/snap.png" alt="" width="300" hight="200">-->
        <!--<p>実行結果</p>-->
        <p>回転処理の前にクラスタリング処理をはさむことで、<br>
            文字列が複数行にわたる画像も回転できるようになった。<br><br>
        </p>
        <h4>空白挿入</h4>
        <p>単語区切りで真っ黒な画像を挿入し認識させる。<br>
        予測値が英数字ともに0.6以下のものを空白として処理する。
        </p>
        <pre class="brush:py">
        breakline = np.zeros((28, 28))
        breakline = breakline.reshape(28, 28, 1)
        breakline = breakline.astype("float32") / 255
        
        letters_list.append(breakline)
        </pre>
        <h4>モデル</h4>
        <p>
        モデルはkerasでCNNを作成。
        </p>
        <pre class="brush:py">
        #英字の認識モデル
        from keras.models import Sequential
        
        def build_model():
            model = Sequential()
            model.add(Conv2D(32, kernel_size=(3, 3),
                             activation='relu',
                             input_shape=(28,28,1)))
            model.add(MaxPooling2D(pool_size=(2, 2)))
            model.add(Flatten())
            model.add(Dense(784, activation='relu'))
            model.add(Dense(52, activation='softmax'))
        </pre>
        <p>基本に忠実に作った。</p>
        <p>参考:</p> 
        <li><a href="http://cs230.stanford.edu/section/">http://cs230.stanford.edu/section/</a></li>
        <li><a href = "https://github.com/kujirahand/book-python-scraping">https://github.com/kujirahand/book-python-scraping</a></li><br>
        
    </div>
  <a href="index.html"><button>戻る</button></a>
</main>
</body>
</html>