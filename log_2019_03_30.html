<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Introduction: original OCR app</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/marx/2.0.4/marx.css">
    <link rel="stylesheet" type="text/css" href="http://alexgorbatchev.com/pub/sh/current/styles/shCoreEclipse.css"/>
    <script type="text/javascript" src="http://alexgorbatchev.com/pub/sh/current/scripts/shCore.js"></script>
    <script type="text/javascript" src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushPython.js"></script>
    <script type="text/javascript">SyntaxHighlighter.all();</script>
</head>

<body>
<main>
    <br>
        <hr>
        <h4>2019/03/30</h4>
        <p>クラスタリングと画像回転はうまくいったものの、その後の空白、改行処理実装が難航ぎみ。<br><br>
            
            cv2.imreadで読み込んだ画像の型はnumpy ndarrayらしい。<br>
        </p>
        <img src="./image/img-type.png" alt="" width="200" hight="200">
        <p>なので、こういう書き方↓で一点のBGR値を読み込める。(y座標:20, x座標:30の場合)</p>
        <pre class="brush:py">
        cv2_img = cv2.imread(path)
        px = cv2_img[20, 30]
        print(px)
        #[206 206 170]
        </pre>
        <p>また、一点だけでなく、指定した領域 (注目領域 : ROI) のBGR値も取得できる。</p>
        <pre class="brush:py">
        px = cv2_img[50:60, 30:40]
        print(px)
        #[[[206 204 169]
        #  [206 204 169]
        #  [208 208 172]
        #  [208 208 172]
        #  [208 208 172]
        #  [208 208 172]
        #  [208 208 172]
        #  [208 208 172]
        #  [207 207 171]
        #  [207 207 171]]
                ・
                ・
                ・
        </pre>
        <p>このように、指定した 10×10=100(pixel) ぶんのBGR値を得られる。<br>
            さらに、抽出した領域を画像 (OpenCVで読み込んで領域指定) や 新たに作成したnumpy ndarrayに張り付けることもできる。<br>
        </p>
        <pre class="brush:py">
            #新たにnumpy ndarrayを作成する場合
            spc = np.zeros((n1, n2))
            spc[y1:y2, x1:x2] = px
        </pre>
        <p>ここの理解が甘くて真っ黒な画像を何枚も抽出してしまった。<br>
        あとは予測時の画像の次元にreshapeするだけだが、kerasの予測モデルに入れる画像の input shape が違うらしくエラーが出ている。<br>
        </p>
        <b><i>ValueError: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_1/convolution' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].</i></b><br><br>
        <p>調べたところ、どうやらモデルの引数の順番がデフォルトと違っていたためらしい。<br>
        引数data_formatにchannels_firstを書き加える。なぜ今まで問題なく動いていたんだろう…。<br>
        </p>
        <pre class="brush:py">
        model.add(Conv2D(32, kernel_size=(3, 3),
                     activation='relu',
                     input_shape=(1,28,28),
                     data_format='channels_first'))
        </pre>
        <p>
        が、結果が思うように出ない。
        </p>
        <b><i>RESULT: M M MY R dG U Ze T e e T N ob T g ...</i></b><br><br>
        
        <p>画像のどこかを誤認識しているのか、そもそも与えるndarrayがおかしいのか、はたまた他の原因か。<br>原因は明日考えることにする。</p>
        <p>参考：
        <a href ="https://docs.opencv.org/3.0.0/d3/df2/tutorial_py_basic_ops.html">https://docs.opencv.org/3.0.0/d3/df2/tutorial_py_basic_ops.html</a>
        <a href= "https://keras.io/layers/convolutional/">https://keras.io/layers/convolutional/</a>
        </p><br>
    <a href="log_index.html"><button>戻る</button></a>
</main>
</body>
</html>